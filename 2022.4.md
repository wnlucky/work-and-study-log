# 2022.4

## 第三周 (4.18~~4.24)

### ToDoList

1. xgpu混部
   
   - [ ] xgpu代码通读
   
   - [ ] 解决死锁问题
   
   - [ ] 做多场景的可靠性测试
     
     - [ ] 单训练
     
     - [ ] 单推理
     
     - [ ] 先训练后推理
     
     - [ ] 先推理后训练
     
     - [ ] 推理 / 训练 挂掉，对彼此的影响
   
   - [ ] 将测试步骤与结果更新到文档中
   
   - [ ] 写一个比较大的kernel(grid/block比较大)，在gpu上跑的时间长一些，查看这种长训练kernel的处理情况 (在qps比较低的时候再launch？？)

2. nccl on xgpu
   
   - [ ] 将修改的gpu oridinal内容合入

3. CI test
   
   - [ ] 将trition加入ci test中
   
   - [ ] 将code coverage加入ci test中

4. *xgpu补充学习
   
   - [ ] antman论文阅读
   
   - [ ] nvidia并行论文阅读

### 

### 4.18 (周一)

1. 测试 kernel burst结束的时机
2. 测试 triton+tensorflow两个容器的情况

#### 进展

1. 完成1项，通过阅读代码，kernel burst结束的时机还是应该在调用cuEventSync的时候

2. 完成2项，表现为训练在推理 / 无推理两种情况下，单位时间内launch kernel数不同，这里有可能是时间片quota造成的，也可能是与推理流量错开造成的，需要区分

3. 学习 shared_ptr/unique_ptr/weak_ptr，[相关链接](https://blog.csdn.net/xiejingfa/category_6048140.html?spm=1001.2014.3001.5482) 

#### 遗留 / 存疑

1. 修改kernel_burst数加减的位置在TraceEventScope构造与析构的时机，在log中观察是否有只加不减的情况

2. 将2个triton安排在2个容器中测试

### 

### 4.19 (周二)

1. 修改kernel_burst数加减位置为TraceEventScope构造/析构

2. 学习cuda stream/event内容

3. 学习std::thread内容

#### 进展

1. 大概完成2、3项

2. 第1项完成，测试没有额外问题

#### 遗留 / 存疑

### 

### 4.20 (周三)

#### 进展

1. xgpu server 切换至最新master，之前训练kernel launch断的情况没有出现，需要与master merge之后再测试

### 

### 4.21 (周四)

1. 与master merge起来，查看training 断流是否消失

2. 测试各个场景下稳定性

3. 修改performance_monitor与TraceEventScope的实现

4. 测试一个较大kernel的训练表现

5. 更新launchkernelcount文档

#### 进展

1. 完成1项(周五)

#### 遗留 / 存疑

### 4.24 (周日)

1. 梳理整体代码
2. 修改performance_monitor与TraceEventScope的实现
3. 写一个较大的kernel，评估训练表现
4. 更新launchkernel count 文档
